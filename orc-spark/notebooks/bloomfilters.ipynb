{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7747c0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- store_id: integer (nullable = true)\n",
      " |-- store_name: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      "\n",
      "+--------+----------+----------+----------+\n",
      "|store_id|store_name|  latitude| longitude|\n",
      "+--------+----------+----------+----------+\n",
      "|       1|   Store_1|  0.511931| 58.357941|\n",
      "|       2|   Store_2|-36.995204|  96.52245|\n",
      "|       3|   Store_3|  1.710979| 136.72836|\n",
      "|       4|   Store_4| 54.362306| 29.325625|\n",
      "|       5|   Store_5| 27.621896|104.960096|\n",
      "|       6|   Store_6|-45.140762| 49.248075|\n",
      "|       7|   Store_7|-25.188553|121.121056|\n",
      "|       8|   Store_8| -7.761529| 39.723312|\n",
      "|       9|   Store_9|-12.534165| 67.932349|\n",
      "|      10|  Store_10| 29.997698|  49.64388|\n",
      "|      11|  Store_11| 50.647739| 41.553978|\n",
      "|      12|  Store_12|  48.74235| 40.406987|\n",
      "|      13|  Store_13|-15.040655| 37.568223|\n",
      "|      14|  Store_14|-12.551707|121.601048|\n",
      "|      15|  Store_15| 67.785301| 22.227968|\n",
      "|      16|  Store_16| -7.946656| 52.700352|\n",
      "|      17|  Store_17|-19.944883|101.980263|\n",
      "|      18|  Store_18| -8.989144| 58.378048|\n",
      "|      19|  Store_19| 21.741408|121.593894|\n",
      "|      20|  Store_20| 27.377348|119.875232|\n",
      "+--------+----------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "‚úÖ ORC file with Bloom filters written at: /home/jovyan/warehouse/db2/stores_orc\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Write ORC with Bloom Filters\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Load CSV file\n",
    "csv_path = \"/home/jovyan/work/stores.csv\"\n",
    "df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(csv_path)\n",
    "\n",
    "# Show schema and preview data (optional)\n",
    "df.printSchema()\n",
    "df.show()\n",
    "\n",
    "# ‚úÖ Define output path inside warehouse\n",
    "output_path = \"/home/jovyan/warehouse/db2/stores_orc\"\n",
    "\n",
    "# Write ORC with Bloom filters\n",
    "df.write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"orc.bloom.filter.columns\", \"store_id,store_name\") \\\n",
    "    .option(\"orc.bloom.filter.fpp\", \"0.01\") \\\n",
    "    .orc(output_path)\n",
    "\n",
    "print(\"‚úÖ ORC file with Bloom filters written at:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2451f002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+----------+----------+\n",
      "|store_id|store_name|  latitude| longitude|\n",
      "+--------+----------+----------+----------+\n",
      "|    1001|Store_1001|-45.310839|135.491436|\n",
      "+--------+----------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.sql(\"SELECT * FROM stores WHERE store_id = 1001\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8d24e17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------+---------+\n",
      "|store_id|store_name|latitude|longitude|\n",
      "+--------+----------+--------+---------+\n",
      "+--------+----------+--------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.sql(\"SELECT * FROM stores WHERE store_id = 10010000\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c14fd2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+---------+----------+\n",
      "|store_id|store_name| latitude| longitude|\n",
      "+--------+----------+---------+----------+\n",
      "|    9999|Store_9999|28.666345|100.853035|\n",
      "+--------+----------+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.orc(\"/home/jovyan/warehouse/db2/stores_orc\")\n",
    "df.createOrReplaceTempView(\"stores\")\n",
    "spark.sql(\"SELECT * FROM stores WHERE store_id = 9999\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b708f280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+----------+----------+\n",
      "|store_id|store_name|  latitude| longitude|\n",
      "+--------+----------+----------+----------+\n",
      "|    1000|Store_1000| 48.929564| 84.683002|\n",
      "|    1001|Store_1001|-45.310839|135.491436|\n",
      "|    1002|Store_1002| -5.560226| 39.690047|\n",
      "|    1003|Store_1003| 30.876063|102.868682|\n",
      "|    1004|Store_1004| 68.899919|124.811859|\n",
      "|    1005|Store_1005| 14.270271|135.468256|\n",
      "|    1006|Store_1006|-32.650969| 65.364078|\n",
      "|    1007|Store_1007|-20.835574| 49.316708|\n",
      "|    1008|Store_1008|-43.921252|130.086826|\n",
      "|    1009|Store_1009|   1.78585| 50.713614|\n",
      "|    1010|Store_1010|-29.727588| 20.171948|\n",
      "|    1011|Store_1011|-19.056635|125.315733|\n",
      "|    1012|Store_1012| 42.442496| 97.082303|\n",
      "|    1013|Store_1013|-39.333889|131.510676|\n",
      "|    1014|Store_1014| 71.499269| 67.577959|\n",
      "|    1015|Store_1015| -27.41883| 26.599881|\n",
      "|    1016|Store_1016| -8.594115|124.142973|\n",
      "|    1017|Store_1017|-37.964524| 67.419656|\n",
      "|    1018|Store_1018|-45.779676| 32.392872|\n",
      "|    1019|Store_1019|  9.177237|126.697686|\n",
      "+--------+----------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM stores WHERE store_id BETWEEN 1000 AND 2000\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ef6ab37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+---------+---------+\n",
      "|store_id|store_name| latitude|longitude|\n",
      "+--------+----------+---------+---------+\n",
      "|     726| Store_726|60.979219|18.152492|\n",
      "|     968| Store_968|68.735934|19.833183|\n",
      "|    1184|Store_1184|57.927689|18.069964|\n",
      "|    1337|Store_1337|68.193193|19.259823|\n",
      "|    1599|Store_1599|57.869179|18.361071|\n",
      "|    1716|Store_1716|72.172562|18.458788|\n",
      "|    1829|Store_1829|64.164541|18.607604|\n",
      "|    1844|Store_1844|61.409051|19.052851|\n",
      "|    1954|Store_1954|60.519879|19.931171|\n",
      "|    1997|Store_1997|56.350953|17.690688|\n",
      "|    2092|Store_2092|61.092167|19.154016|\n",
      "|    2308|Store_2308|59.617544|18.425325|\n",
      "|    2611|Store_2611|71.579405|18.198438|\n",
      "|    2836|Store_2836|57.019163|19.894856|\n",
      "|    3179|Store_3179|57.500284|18.182368|\n",
      "|    3328|Store_3328|68.897401|18.753454|\n",
      "|    3428|Store_3428|70.136871|17.696811|\n",
      "|    3605|Store_3605|68.041155|18.715164|\n",
      "|    3797|Store_3797|56.260253|19.868176|\n",
      "|    4155|Store_4155|73.309743|18.363168|\n",
      "+--------+----------+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4282"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = spark.sql(\"SELECT * FROM stores where latitude > 55 and longitude < 20\")\n",
    "df2.show()\n",
    "df2.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2bae23a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema: struct<store_id:int,store_name:string,latitude:double,longitude:double>\n",
      "Number of rows: 163554\n",
      "‚úÖ Compression: SNAPPY\n",
      "‚úÖ Compression Block Size: 262144\n",
      "‚úÖ Format Version: (0, 12)\n",
      "‚úÖ Number of Stripes: 1\n",
      "<bound method Reader.read_stripe of <pyorc.reader.Reader object at 0xffff48b50890>>\n",
      "{'content_length': 3743210, 'file_footer_length': 298, 'file_postscript_length': 25, 'file_length': 3743695, 'stripe_statistics_length': 161}\n",
      "{'org.apache.spark.version': b'3.5.0'}\n"
     ]
    }
   ],
   "source": [
    "import pyorc\n",
    "\n",
    "orc_file = \"/home/jovyan/warehouse/db2/stores_orc/part-00005-9aa8ec4a-3763-4967-be92-2507c58a6b83-c000.snappy.orc\"\n",
    "\n",
    "\n",
    "with open(orc_file, \"rb\") as f:\n",
    "    reader = pyorc.Reader(f)\n",
    "\n",
    "    # Schema\n",
    "    print(\"Schema:\", reader.schema)\n",
    "\n",
    "    stride = reader.row_index_stride\n",
    "    all_rows = list(reader)\n",
    "    total_rows = len(all_rows)\n",
    "    print(\"Number of rows:\", total_rows)\n",
    "\n",
    "    # Stripe count\n",
    "    print(\"‚úÖ Compression:\", reader.compression.name) \n",
    "    print(\"‚úÖ Compression Block Size:\", reader.compression_block_size)\n",
    "    print(\"‚úÖ Format Version:\", reader.format_version)\n",
    "    print(\"‚úÖ Number of Stripes:\", reader.num_of_stripes)\n",
    "    print(reader.read_stripe)\n",
    "    print(reader.bytes_lengths)\n",
    "    print(reader.user_metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f1dcb54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Might contain 496164? -> True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pybloom_live import BloomFilter\n",
    "\n",
    "# Create Spark session\n",
    "spark = SparkSession.builder.appName(\"BloomFilterCheck\").getOrCreate()\n",
    "\n",
    "# Read ORC file\n",
    "df = spark.read.orc(\"/home/jovyan/warehouse/db2/stores_orc/part-00003-9aa8ec4a-3763-4967-be92-2507c58a6b83-c000.snappy.orc\")\n",
    "\n",
    "# Collect store_id values locally (assumes it's not huge)\n",
    "store_ids = df.select(\"store_id\").rdd.map(lambda row: row[\"store_id\"]).collect()\n",
    "\n",
    "# Create a local Bloom filter\n",
    "bf = BloomFilter(capacity=1000000, error_rate=0.01)\n",
    "\n",
    "# Populate Bloom filter\n",
    "for store_id in store_ids:\n",
    "    bf.add(store_id)\n",
    "\n",
    "# Check if a store_id might be present\n",
    "check_id = 496164\n",
    "print(f\"Might contain {check_id}? ->\", check_id in bf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "925c9042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------+----------+----------+\n",
      "|store_id|  store_name|  latitude| longitude|\n",
      "+--------+------------+----------+----------+\n",
      "|  496164|Store_496164|  54.16662| 96.719518|\n",
      "|  496165|Store_496165| 20.043097| 95.314145|\n",
      "|  496166|Store_496166| 59.636568|    96.726|\n",
      "|  496167|Store_496167|-38.094901|130.127986|\n",
      "|  496168|Store_496168|-45.216044| 47.550081|\n",
      "|  496169|Store_496169| 51.802525|136.360378|\n",
      "|  496170|Store_496170| 55.026124| 61.290989|\n",
      "|  496171|Store_496171|-46.327335| 54.417178|\n",
      "|  496172|Store_496172| 41.134244| 73.314949|\n",
      "|  496173|Store_496173| 46.194376| 71.531106|\n",
      "|  496174|Store_496174| -1.726265|111.354441|\n",
      "|  496175|Store_496175|-31.114968|  24.28303|\n",
      "|  496176|Store_496176| -4.361737| 94.675499|\n",
      "|  496177|Store_496177| 65.778544| 42.340798|\n",
      "|  496178|Store_496178| 44.074423| 70.056797|\n",
      "|  496179|Store_496179|-38.637158| 51.914682|\n",
      "|  496180|Store_496180| 23.301149| 47.103871|\n",
      "|  496181|Store_496181| 26.623572| 43.692912|\n",
      "|  496182|Store_496182| 48.348829|119.134447|\n",
      "|  496183|Store_496183|  -32.8288|   53.7173|\n",
      "+--------+------------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.orc(\"/home/jovyan/warehouse/db2/stores_orc/part-00003-9aa8ec4a-3763-4967-be92-2507c58a6b83-c000.snappy.orc\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "521f30e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+-----------------+\n",
      "|count|min   |max   |bloom_test_496164|\n",
      "+-----+------+------+-----------------+\n",
      "|10000|496165|659719|false            |\n",
      "|10000|496173|659709|false            |\n",
      "|10000|496166|659714|false            |\n",
      "|10000|496183|659718|false            |\n",
      "|889  |496167|659617|false            |\n",
      "|10000|496172|659707|false            |\n",
      "|10000|496179|659711|false            |\n",
      "|10000|496169|659684|false            |\n",
      "|10000|496174|659702|false            |\n",
      "|889  |496580|659616|false            |\n",
      "|10000|496168|659708|false            |\n",
      "|10000|496177|659697|false            |\n",
      "|10000|496205|659713|false            |\n",
      "|10000|496171|659716|false            |\n",
      "|889  |496190|659636|false            |\n",
      "|10000|496185|659698|false            |\n",
      "|10000|496175|659715|false            |\n",
      "|10000|496164|659689|true             |\n",
      "|10000|496181|659712|false            |\n",
      "|889  |496263|659594|false            |\n",
      "+-----+------+------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "from pybloom_live import BloomFilter\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"StripeStatsBloomDF\").getOrCreate()\n",
    "\n",
    "# Read ORC file\n",
    "df = spark.read.orc(\"/home/jovyan/warehouse/db2/stores_orc/part-00003-9aa8ec4a-3763-4967-be92-2507c58a6b83-c000.snappy.orc\")\n",
    "\n",
    "# Optional: Repartition to simulate stripe-like chunks\n",
    "df = df.repartition(4)\n",
    "\n",
    "# Define function to apply on each partition using Pandas\n",
    "def bloom_partition_stats(pdf_iter):\n",
    "    for pdf in pdf_iter:\n",
    "        if 'store_id' not in pdf.columns or pdf.empty:\n",
    "            continue\n",
    "        \n",
    "        store_ids = pdf['store_id'].dropna().tolist()\n",
    "        if not store_ids:\n",
    "            continue\n",
    "\n",
    "        bf = BloomFilter(capacity=10000000, error_rate=0.01)\n",
    "        for sid in store_ids:\n",
    "            bf.add(sid)\n",
    "\n",
    "        # We can't return BloomFilter directly, so store needed info\n",
    "        yield pd.DataFrame([{\n",
    "            \"count\": len(store_ids),\n",
    "            \"min\": min(store_ids),\n",
    "            \"max\": max(store_ids),\n",
    "            \"bloom_test_496164\": 496164 in bf\n",
    "        }])\n",
    "\n",
    "# Use mapInPandas to process partitions\n",
    "result_df = df.select(\"store_id\").mapInPandas(bloom_partition_stats, schema=\"count int, min long, max long, bloom_test_496164 boolean\")\n",
    "\n",
    "# Show results\n",
    "result_df.show(truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c4e4dc0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stripe 0 has Bloom filters on columns: 0\n"
     ]
    }
   ],
   "source": [
    "import pyorc\n",
    "\n",
    "# Assuming you have an ORC file named 'my_data.orc'\n",
    "with open('/home/jovyan/warehouse/db2/stores_orc/part-00005-9aa8ec4a-3763-4967-be92-2507c58a6b83-c000.snappy.orc', 'rb') as orc_file:\n",
    "    reader = pyorc.Reader(orc_file)\n",
    "\n",
    "    # Iterate through each stripe\n",
    "    for stripe_index in range(reader.num_of_stripes):\n",
    "        stripe = reader.read_stripe(stripe_index)\n",
    "\n",
    "        # Check for columns with Bloom filters in the current stripe\n",
    "        if stripe.bloom_filter_columns:\n",
    "            print(f\"Stripe {stripe_index} has Bloom filters on columns: {stripe.row_offset}\")\n",
    "\n",
    "           \n",
    "        else:\n",
    "            print(f\"Stripe {stripe_index} does not have Bloom filters on any columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2056f106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema: struct<store_id:int,store_name:string,latitude:double,longitude:double>\n",
      "Compression: SNAPPY\n",
      "Compression Block Size: 262144\n",
      "Stripe count: 1\n",
      "\n",
      "Column Stats:\n",
      "store_id: {'min': 823269, 'max': 986822, 'nulls': 0, 'count': 163554}\n",
      "store_name: {'min': 'Store_823269', 'max': 'Store_986822', 'nulls': 0, 'count': 163554}\n",
      "latitude: {'min': -47.526959, 'max': 73.470142, 'nulls': 0, 'count': 163554}\n",
      "longitude: {'min': 17.095456, 'max': 138.092932, 'nulls': 0, 'count': 163554}\n"
     ]
    }
   ],
   "source": [
    "import pyorc\n",
    "from collections import defaultdict\n",
    "\n",
    "orc_path = \"/home/jovyan/warehouse/db2/stores_orc/part-00005-9aa8ec4a-3763-4967-be92-2507c58a6b83-c000.snappy.orc\"\n",
    "\n",
    "# Holds stats per column\n",
    "stats = defaultdict(lambda: {\"min\": None, \"max\": None, \"nulls\": 0, \"count\": 0})\n",
    "\n",
    "with open(orc_path, \"rb\") as data:\n",
    "    reader = pyorc.Reader(data)\n",
    "    schema = reader.schema\n",
    "    print(\"Schema:\", schema)\n",
    "    print(\"Compression:\", reader.compression.name)\n",
    "    print(\"Compression Block Size:\", reader.compression_block_size)\n",
    "    print(\"Stripe count:\", reader.num_of_stripes)\n",
    "    #print(\"Total rows:\", reader.number_of_rows)\n",
    "\n",
    "    if hasattr(schema, \"fields\"):\n",
    "        field_names = list(schema.fields.keys())\n",
    "    else:\n",
    "        field_names = [f\"col{i}\" for i in range(len(reader.schema))]  # fallback\n",
    "\n",
    "    # ‚úÖ Iterate over each row and calculate stats\n",
    "    for row in reader:\n",
    "        for i, value in enumerate(row):\n",
    "            field = field_names[i]\n",
    "            if value is None:\n",
    "                stats[field][\"nulls\"] += 1\n",
    "            else:\n",
    "                stats[field][\"count\"] += 1\n",
    "                if stats[field][\"min\"] is None or value < stats[field][\"min\"]:\n",
    "                    stats[field][\"min\"] = value\n",
    "                if stats[field][\"max\"] is None or value > stats[field][\"max\"]:\n",
    "                    stats[field][\"max\"] = value\n",
    "\n",
    "# ‚úÖ Print results\n",
    "print(\"\\nColumn Stats:\")\n",
    "for col, stat in stats.items():\n",
    "    print(f\"{col}: {stat}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f23a710a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema: struct<store_id:int,store_name:string,latitude:double,longitude:double>\n",
      "Compression: SNAPPY\n",
      "Compression Block Size: 262144\n",
      "Stripe count: 1\n",
      "Bytes lengths: {'content_length': 3743210, 'file_footer_length': 298, 'file_postscript_length': 25, 'file_length': 3743695, 'stripe_statistics_length': 161}\n",
      "{'org.apache.spark.version': b'3.5.0'}\n",
      "10000\n",
      "163554\n",
      "163554\n",
      "3\n",
      "0\n",
      "\n",
      "üì¶ Stripe 0 (Rows: 163554)\n",
      "  ‚ñ∏ store_id: min=823269 max=986822 nulls=0 count=163554\n",
      "  ‚ñ∏ store_name: min=Store_823269 max=Store_986822 nulls=0 count=163554\n",
      "  ‚ñ∏ latitude: min=-47.526959 max=73.470142 nulls=0 count=163554\n",
      "  ‚ñ∏ longitude: min=17.095456 max=138.092932 nulls=0 count=163554\n"
     ]
    }
   ],
   "source": [
    "import pyorc\n",
    "from collections import defaultdict\n",
    "\n",
    "orc_path = \"/home/jovyan/warehouse/db2/stores_orc/part-00005-9aa8ec4a-3763-4967-be92-2507c58a6b83-c000.snappy.orc\"\n",
    "\n",
    "with open(orc_path, \"rb\") as data:\n",
    "    reader = pyorc.Reader(data)\n",
    "    schema = reader.schema\n",
    "    stripe_count = reader.num_of_stripes\n",
    "\n",
    "    print(\"Schema:\", schema)\n",
    "    print(\"Compression:\", reader.compression.name)\n",
    "    print(\"Compression Block Size:\", reader.compression_block_size)\n",
    "    print(\"Stripe count:\", stripe_count)\n",
    "    print(\"Bytes lengths:\", reader.bytes_lengths)\n",
    "    print(reader.user_metadata)\n",
    "    print(reader.row_index_stride)\n",
    "    print(reader.__len__())\n",
    "    print(stripe.__len__())\n",
    "    print(stripe.bytes_offset)\n",
    "    print(stripe.row_offset)\n",
    "\n",
    "    field_names = list(schema.fields.keys()) if hasattr(schema, \"fields\") else [f\"col{i}\" for i in range(len(reader.schema))]\n",
    "\n",
    "    # Simulate per-stripe stats\n",
    "    for stripe_index in range(stripe_count):\n",
    "        stripe_stats = defaultdict(lambda: {\"min\": None, \"max\": None, \"nulls\": 0, \"count\": 0})\n",
    "        rows = reader.read_stripe(stripe_index)\n",
    "\n",
    "        print(f\"\\nüì¶ Stripe {stripe_index} (Rows: {len(rows)})\")\n",
    "        for row in rows:\n",
    "            for i, value in enumerate(row):\n",
    "                field = field_names[i]\n",
    "                if value is None:\n",
    "                    stripe_stats[field][\"nulls\"] += 1\n",
    "                else:\n",
    "                    stripe_stats[field][\"count\"] += 1\n",
    "                    if stripe_stats[field][\"min\"] is None or value < stripe_stats[field][\"min\"]:\n",
    "                        stripe_stats[field][\"min\"] = value\n",
    "                    if stripe_stats[field][\"max\"] is None or value > stripe_stats[field][\"max\"]:\n",
    "                        stripe_stats[field][\"max\"] = value\n",
    "\n",
    "        # Print stripe stats\n",
    "        for field in field_names:\n",
    "            stat = stripe_stats[field]\n",
    "            print(f\"  ‚ñ∏ {field}: min={stat['min']} max={stat['max']} nulls={stat['nulls']} count={stat['count']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "85fe8bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema: struct<store_id:int,store_name:string,latitude:double,longitude:double>\n",
      "Compression: SNAPPY\n",
      "Compression Block Size: 262144\n",
      "Stripe count: 1\n",
      "Total Rows 163554\n",
      "stripe.bytes_offset: 3\n",
      "stripe.row_offset: 0\n",
      "\n",
      "üì¶ Stripe 0 (Rows: 163554)\n",
      "  ‚ñ∏ store_id: min=823269 max=986822 nulls=0 count=163554\n",
      "  ‚ñ∏ store_name: min=Store_823269 max=Store_986822 nulls=0 count=163554\n",
      "  ‚ñ∏ latitude: min=-47.526959 max=73.470142 nulls=0 count=163554\n",
      "  ‚ñ∏ longitude: min=17.095456 max=138.092932 nulls=0 count=163554\n"
     ]
    }
   ],
   "source": [
    "import pyorc\n",
    "from collections import defaultdict\n",
    "\n",
    "orc_path = \"/home/jovyan/warehouse/db2/stores_orc/part-00005-9aa8ec4a-3763-4967-be92-2507c58a6b83-c000.snappy.orc\"\n",
    "\n",
    "with open(orc_path, \"rb\") as data:\n",
    "    reader = pyorc.Reader(data)\n",
    "    schema = reader.schema\n",
    "    stripe_count = reader.num_of_stripes\n",
    "\n",
    "    print(\"Schema:\", schema)\n",
    "    print(\"Compression:\", reader.compression.name)\n",
    "    print(\"Compression Block Size:\", reader.compression_block_size)\n",
    "    print(\"Stripe count:\", stripe_count)\n",
    "    print(\"Total Rows\", reader.__len__())\n",
    "\n",
    "    \n",
    "    try:\n",
    "        # This will raise an error because `stripe` is not defined\n",
    "        \n",
    "        print(\"stripe.bytes_offset:\", stripe.bytes_offset)\n",
    "        print(\"stripe.row_offset:\", stripe.row_offset)\n",
    "    except NameError:\n",
    "        print(\"‚ö†Ô∏è  'stripe' is not defined ‚Äî these attributes are not accessible via pyorc.\")\n",
    "\n",
    "    # Get column names\n",
    "    field_names = list(schema.fields.keys()) if hasattr(schema, \"fields\") else [f\"col{i}\" for i in range(len(reader.schema))]\n",
    "\n",
    "    # Simulate per-stripe stats\n",
    "    for stripe_index in range(stripe_count):\n",
    "        stripe_stats = defaultdict(lambda: {\"min\": None, \"max\": None, \"nulls\": 0, \"count\": 0})\n",
    "        rows = reader.read_stripe(stripe_index)\n",
    "\n",
    "        print(f\"\\nüì¶ Stripe {stripe_index} (Rows: {len(rows)})\")\n",
    "        for row in rows:\n",
    "            for i, value in enumerate(row):\n",
    "                field = field_names[i]\n",
    "                if value is None:\n",
    "                    stripe_stats[field][\"nulls\"] += 1\n",
    "                else:\n",
    "                    stripe_stats[field][\"count\"] += 1\n",
    "                    if stripe_stats[field][\"min\"] is None or value < stripe_stats[field][\"min\"]:\n",
    "                        stripe_stats[field][\"min\"] = value\n",
    "                    if stripe_stats[field][\"max\"] is None or value > stripe_stats[field][\"max\"]:\n",
    "                        stripe_stats[field][\"max\"] = value\n",
    "\n",
    "        # Print stripe stats\n",
    "        for field in field_names:\n",
    "            stat = stripe_stats[field]\n",
    "            print(f\"  ‚ñ∏ {field}: min={stat['min']} max={stat['max']} nulls={stat['nulls']} count={stat['count']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
